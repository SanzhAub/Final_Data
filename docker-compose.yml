version: "3.8"

services:
  # Zookeeper –¥–ª—è Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # Kafka
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    command: >
      bash -c "
        echo '–ó–∞–ø—É—Å–∫ Kafka...' &&
        /etc/confluent/docker/run &
        sleep 20 &&
        kafka-topics --create --topic raw_weather_events --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1 --if-not-exists &&
        echo '‚úÖ Kafka –≥–æ—Ç–æ–≤. –¢–æ–ø–∏–∫ raw_weather_events —Å–æ–∑–¥–∞–Ω' &&
        tail -f /dev/null
      "

  airflow:
    image: apache/airflow:2.7.0-python3.10
    container_name: airflow
    env_file:
      - .env
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "true"

      WEATHERAPI_KEY: ${WEATHERAPI_KEY}
      WEATHER_LOCATION: Almaty
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: raw_weather_events
      PRODUCER_INTERVAL: "30"

      KAFKA_CONSUMER_GROUP: weather_batch_processor
      BATCH_HOURS_BACK: "1"
      DATA_DIR: /opt/airflow/data

      AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL: 30
      AIRFLOW__WEBSERVER__WORKERS: 2
      AIRFLOW__WEBSERVER__WEB_SERVER_PORT: 8080
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./src:/opt/airflow/src
      - ./data:/opt/airflow/data
      - ./requirements.txt:/opt/airflow/requirements.txt
      - airflow_db:/opt/airflow
    ports:
      - "8080:8080"
    command: >
      bash -c "
        echo 'üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Airflow –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞...' &&
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        airflow db init &&
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com && 
        echo '‚úÖ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å admin —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç' &&
        
        echo 'üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏–∑ requirements.txt...' &&
        pip install -r /opt/airflow/requirements.txt &&
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º scheduler –≤ —Ñ–æ–Ω–µ
        echo 'üöÄ –ó–∞–ø—É—Å–∫ Airflow Scheduler...' &&
        airflow scheduler &
        
        # –î–∞–µ–º scheduler –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—É—Å–∫
        sleep 10 &&
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º webserver
        echo 'üåê –ó–∞–ø—É—Å–∫ Airflow Webserver...' &&
        echo '======================================' &&
        echo '‚úÖ Airflow –≥–æ—Ç–æ–≤!' &&
        echo 'üåê –î–æ—Å—Ç—É–ø: http://localhost:8080' &&
        echo 'üë§ –õ–æ–≥–∏–Ω: admin' &&
        echo 'üîë –ü–∞—Ä–æ–ª—å: admin' &&
        echo '======================================' &&
        exec airflow webserver
      "
    depends_on:
      - kafka
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 10

volumes:
  airflow_db:
